<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.1" />
<title>tsteno.language.tokenizer API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>tsteno.language.tokenizer</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import string
import tsteno.language.token_list as token_list


class Token:
    __slots__ = (&#39;type&#39;, &#39;val&#39;, &#39;pos&#39;)

    def __init__(self, toktype, tokval, pos):
        self.val = tokval
        self.type = toktype
        self.pos = pos

    def get_value(self):
        return self.val

    def get_type(self):
        return self.type

    def __repr__(self):
        return &#34;{} : {}&#34;.format(self.type, self.val)


class BaseTokenReader:
    def __init__(self):
        pass

    def match(self, character):
        raise Exception(&#34;Undefined class reference&#34;)

    def calculate(self, code, pos, max_len):
        raise Exception(&#34;Undefined class reference&#34;)


class NumberTokenReader(BaseTokenReader):
    def match(self, character):
        return character.isdigit()

    def calculate(self, code, pos, max_len):
        num_buffer = []
        num_cls = int

        while pos &lt; max_len:
            if not code[pos].isdigit() and (
                code[pos] != &#39;.&#39; or
                code[pos] in num_buffer
            ) and code[pos] != &#39;`&#39;:
                break

            if code[pos] == &#39;.&#39;:
                num_cls = float

            if code[pos] != &#39;`&#39;:
                num_buffer.append(code[pos])
            pos = pos + 1
            continue

        return Token(
            token_list.TOKEN_NUMBER, num_cls(&#34;&#34;.join(num_buffer)), pos
        ), pos


class StringTokenReader(BaseTokenReader):

    def match(self, character):
        return character == &#34;\&#34;&#34;

    def calculate(self, code, pos, max_len):
        characters = []

        pos = pos + 1
        while pos &lt; max_len:
            if code[pos] == &#34;\&#34;&#34; and code[pos - 1] != &#34;\\&#34;:
                return Token(
                    token_list.TOKEN_STRING, &#34;&#34;.join(characters), pos
                ), pos + 1
            if code[pos] == &#34;\\&#34;:
                pos = pos + 1
                continue
            characters.append(code[pos])
            pos = pos + 1

        raise TokenError(&#39;Unknown character&#39;, code, pos, max_len)


class IdentifierTokenReader(BaseTokenReader):
    OK_CHARACTERS = [&#39;_&#39;]

    def match(self, character):
        return character is not None and (
            character in string.ascii_letters or
            character in IdentifierTokenReader.OK_CHARACTERS
        )

    def calculate(self, code, pos, max_len):
        characters = []

        while pos &lt; max_len and (
            self.match(code[pos]) or
            code[pos].isdigit() or
            code[pos] in [&#39;_&#39;]
        ):
            characters.append(code[pos])
            pos = pos + 1

        return Token(
            token_list.TOKEN_IDENTIFIER, &#34;&#34;.join(characters), pos
        ), pos


class MiscTokenReader(BaseTokenReader):
    TOKEN_REFERENCES = {
        # Operations
        &#39;+&#39;: token_list.TOKEN_OP,
        &#39;-&#39;: token_list.TOKEN_OP,
        &#39;*&#39;: token_list.TOKEN_OP,
        &#39;/&#39;: token_list.TOKEN_OP,
        &#39;:&#39;: token_list.TOKEN_OP,
        &#39;=&#39;: token_list.TOKEN_OP,
        &#39;^&#39;: token_list.TOKEN_OP,
        &#39;&lt;&#39;: token_list.TOKEN_OP,
        &#39;&gt;&#39;: token_list.TOKEN_OP,
        &#39;.&#39;: token_list.TOKEN_OP,
        &#39;!&#39;: token_list.TOKEN_OP,
        &#39;`&#39;: token_list.TOKEN_OP,

        # OP order
        &#39;(&#39;: token_list.TOKEN_LEFTPAREN,
        &#39;)&#39;: token_list.TOKEN_RIGHTPAREN,

        # Functions
        &#39;[&#39;: token_list.TOKEN_LEFTSQUARE_BRACKETS,
        &#39;]&#39;: token_list.TOKEN_RIGHTSQUARE_BRACKETS,
        &#39;,&#39;: token_list.TOKEN_COMMA_SEPARATOR,

        &#39;{&#39;: token_list.TOKEN_LEFTLIST,
        &#39;}&#39;: token_list.TOKEN_RIGHTLIST,

        &#34;\n&#34;: token_list.TOKEN_NEWLINE,
        &#34;;&#34;: token_list.TOKEN_CLOSE_EXPR,
    }

    def __init__(self):
        super().__init__()
        self.character_list = MiscTokenReader.TOKEN_REFERENCES.keys()

    def match(self, character):
        return character in self.character_list

    def calculate(self, code, pos, max_len):
        return Token(
            MiscTokenReader.TOKEN_REFERENCES[code[pos]], code[pos], pos
        ), pos + 1


class TokenError(Exception):
    __slots__ = (&#39;error_message&#39;)

    def __init__(self, msg, code, pos, max_len):
        col = 0
        lin = 0
        i = 0

        while i &lt; pos:
            if code[i] == &#34;\n&#34;:
                col = 0
                lin = lin + 1
            else:
                col = col + 1
            i = i + 1

        lines = code.split(&#34;\n&#34;)

        extra_information = &#34;\n{}\n{}&#34;.format(
            lines[0], (&#39; &#39; * (col)) + &#39;^&#39;
        )

        character = code[pos] if pos &lt; max_len else &#39;EOF&#39;
        self.error_message = &#34;{} `{}` near line {} and column {}: {}&#34;.format(
            msg, character, lin + 1, col + 1, extra_information
        )

    def __str__(self):
        return self.error_message


class Tokenizer:
    __slots__ = (&#39;token_processors&#39;)

    def __init__(self):
        self.token_processors = [
            NumberTokenReader(), MiscTokenReader(),
            StringTokenReader(), IdentifierTokenReader()
        ]

    def skip_comments(self, pos, max_len, code):
        if pos + 1 &lt; max_len and code[pos] == &#39;(&#39; and code[pos + 1] == &#39;*&#39;:
            while pos + 1 &lt; max_len:
                if code[pos] == &#39;*&#39; and code[pos + 1] == &#39;)&#39;:
                    pos = pos + 2
                    break
                pos = pos + 1
            if pos &gt;= max_len:
                return pos, True
        return pos, False

    def skip_blankspaces(self, code, pos, max_len):
        while pos &lt; max_len and (code[pos] == &#34;\n&#34; or code[pos] == &#39; &#39;):
            pos = pos + 1

        return pos

    def get_tokens(self, code):
        pos = 0
        max_len = len(code)
        last_token = Token(token_list.TOKEN_NOTOKEN, &#39;&#39;, pos)

        while pos &lt; max_len:

            previous_pos = -1

            while previous_pos != pos:
                previous_pos = pos
                pos, ended = self.skip_comments(pos, max_len, code)
                pos = self.skip_blankspaces(code, pos, max_len)

                if pos &gt;= max_len:
                    break

            if pos &gt;= max_len:
                break

            last_token, pos = self.get_next_token(code, pos, max_len)
            yield last_token

    def get_next_token(self, code, pos, max_len):
        for processor in self.token_processors:
            if processor.match(code[pos]):
                return processor.calculate(code, pos, max_len)

        raise TokenError(&#39;Unknown character&#39;, code, pos, max_len)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="tsteno.language.tokenizer.BaseTokenReader"><code class="flex name class">
<span>class <span class="ident">BaseTokenReader</span></span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class BaseTokenReader:
    def __init__(self):
        pass

    def match(self, character):
        raise Exception(&#34;Undefined class reference&#34;)

    def calculate(self, code, pos, max_len):
        raise Exception(&#34;Undefined class reference&#34;)</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="tsteno.language.tokenizer.IdentifierTokenReader" href="#tsteno.language.tokenizer.IdentifierTokenReader">IdentifierTokenReader</a></li>
<li><a title="tsteno.language.tokenizer.MiscTokenReader" href="#tsteno.language.tokenizer.MiscTokenReader">MiscTokenReader</a></li>
<li><a title="tsteno.language.tokenizer.NumberTokenReader" href="#tsteno.language.tokenizer.NumberTokenReader">NumberTokenReader</a></li>
<li><a title="tsteno.language.tokenizer.StringTokenReader" href="#tsteno.language.tokenizer.StringTokenReader">StringTokenReader</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="tsteno.language.tokenizer.BaseTokenReader.calculate"><code class="name flex">
<span>def <span class="ident">calculate</span></span>(<span>self, code, pos, max_len)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate(self, code, pos, max_len):
    raise Exception(&#34;Undefined class reference&#34;)</code></pre>
</details>
</dd>
<dt id="tsteno.language.tokenizer.BaseTokenReader.match"><code class="name flex">
<span>def <span class="ident">match</span></span>(<span>self, character)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def match(self, character):
    raise Exception(&#34;Undefined class reference&#34;)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="tsteno.language.tokenizer.IdentifierTokenReader"><code class="flex name class">
<span>class <span class="ident">IdentifierTokenReader</span></span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class IdentifierTokenReader(BaseTokenReader):
    OK_CHARACTERS = [&#39;_&#39;]

    def match(self, character):
        return character is not None and (
            character in string.ascii_letters or
            character in IdentifierTokenReader.OK_CHARACTERS
        )

    def calculate(self, code, pos, max_len):
        characters = []

        while pos &lt; max_len and (
            self.match(code[pos]) or
            code[pos].isdigit() or
            code[pos] in [&#39;_&#39;]
        ):
            characters.append(code[pos])
            pos = pos + 1

        return Token(
            token_list.TOKEN_IDENTIFIER, &#34;&#34;.join(characters), pos
        ), pos</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="tsteno.language.tokenizer.BaseTokenReader" href="#tsteno.language.tokenizer.BaseTokenReader">BaseTokenReader</a></li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="tsteno.language.tokenizer.IdentifierTokenReader.OK_CHARACTERS"><code class="name">var <span class="ident">OK_CHARACTERS</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="tsteno.language.tokenizer.IdentifierTokenReader.calculate"><code class="name flex">
<span>def <span class="ident">calculate</span></span>(<span>self, code, pos, max_len)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate(self, code, pos, max_len):
    characters = []

    while pos &lt; max_len and (
        self.match(code[pos]) or
        code[pos].isdigit() or
        code[pos] in [&#39;_&#39;]
    ):
        characters.append(code[pos])
        pos = pos + 1

    return Token(
        token_list.TOKEN_IDENTIFIER, &#34;&#34;.join(characters), pos
    ), pos</code></pre>
</details>
</dd>
<dt id="tsteno.language.tokenizer.IdentifierTokenReader.match"><code class="name flex">
<span>def <span class="ident">match</span></span>(<span>self, character)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def match(self, character):
    return character is not None and (
        character in string.ascii_letters or
        character in IdentifierTokenReader.OK_CHARACTERS
    )</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="tsteno.language.tokenizer.MiscTokenReader"><code class="flex name class">
<span>class <span class="ident">MiscTokenReader</span></span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class MiscTokenReader(BaseTokenReader):
    TOKEN_REFERENCES = {
        # Operations
        &#39;+&#39;: token_list.TOKEN_OP,
        &#39;-&#39;: token_list.TOKEN_OP,
        &#39;*&#39;: token_list.TOKEN_OP,
        &#39;/&#39;: token_list.TOKEN_OP,
        &#39;:&#39;: token_list.TOKEN_OP,
        &#39;=&#39;: token_list.TOKEN_OP,
        &#39;^&#39;: token_list.TOKEN_OP,
        &#39;&lt;&#39;: token_list.TOKEN_OP,
        &#39;&gt;&#39;: token_list.TOKEN_OP,
        &#39;.&#39;: token_list.TOKEN_OP,
        &#39;!&#39;: token_list.TOKEN_OP,
        &#39;`&#39;: token_list.TOKEN_OP,

        # OP order
        &#39;(&#39;: token_list.TOKEN_LEFTPAREN,
        &#39;)&#39;: token_list.TOKEN_RIGHTPAREN,

        # Functions
        &#39;[&#39;: token_list.TOKEN_LEFTSQUARE_BRACKETS,
        &#39;]&#39;: token_list.TOKEN_RIGHTSQUARE_BRACKETS,
        &#39;,&#39;: token_list.TOKEN_COMMA_SEPARATOR,

        &#39;{&#39;: token_list.TOKEN_LEFTLIST,
        &#39;}&#39;: token_list.TOKEN_RIGHTLIST,

        &#34;\n&#34;: token_list.TOKEN_NEWLINE,
        &#34;;&#34;: token_list.TOKEN_CLOSE_EXPR,
    }

    def __init__(self):
        super().__init__()
        self.character_list = MiscTokenReader.TOKEN_REFERENCES.keys()

    def match(self, character):
        return character in self.character_list

    def calculate(self, code, pos, max_len):
        return Token(
            MiscTokenReader.TOKEN_REFERENCES[code[pos]], code[pos], pos
        ), pos + 1</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="tsteno.language.tokenizer.BaseTokenReader" href="#tsteno.language.tokenizer.BaseTokenReader">BaseTokenReader</a></li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="tsteno.language.tokenizer.MiscTokenReader.TOKEN_REFERENCES"><code class="name">var <span class="ident">TOKEN_REFERENCES</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="tsteno.language.tokenizer.MiscTokenReader.calculate"><code class="name flex">
<span>def <span class="ident">calculate</span></span>(<span>self, code, pos, max_len)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate(self, code, pos, max_len):
    return Token(
        MiscTokenReader.TOKEN_REFERENCES[code[pos]], code[pos], pos
    ), pos + 1</code></pre>
</details>
</dd>
<dt id="tsteno.language.tokenizer.MiscTokenReader.match"><code class="name flex">
<span>def <span class="ident">match</span></span>(<span>self, character)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def match(self, character):
    return character in self.character_list</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="tsteno.language.tokenizer.NumberTokenReader"><code class="flex name class">
<span>class <span class="ident">NumberTokenReader</span></span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class NumberTokenReader(BaseTokenReader):
    def match(self, character):
        return character.isdigit()

    def calculate(self, code, pos, max_len):
        num_buffer = []
        num_cls = int

        while pos &lt; max_len:
            if not code[pos].isdigit() and (
                code[pos] != &#39;.&#39; or
                code[pos] in num_buffer
            ) and code[pos] != &#39;`&#39;:
                break

            if code[pos] == &#39;.&#39;:
                num_cls = float

            if code[pos] != &#39;`&#39;:
                num_buffer.append(code[pos])
            pos = pos + 1
            continue

        return Token(
            token_list.TOKEN_NUMBER, num_cls(&#34;&#34;.join(num_buffer)), pos
        ), pos</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="tsteno.language.tokenizer.BaseTokenReader" href="#tsteno.language.tokenizer.BaseTokenReader">BaseTokenReader</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="tsteno.language.tokenizer.NumberTokenReader.calculate"><code class="name flex">
<span>def <span class="ident">calculate</span></span>(<span>self, code, pos, max_len)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate(self, code, pos, max_len):
    num_buffer = []
    num_cls = int

    while pos &lt; max_len:
        if not code[pos].isdigit() and (
            code[pos] != &#39;.&#39; or
            code[pos] in num_buffer
        ) and code[pos] != &#39;`&#39;:
            break

        if code[pos] == &#39;.&#39;:
            num_cls = float

        if code[pos] != &#39;`&#39;:
            num_buffer.append(code[pos])
        pos = pos + 1
        continue

    return Token(
        token_list.TOKEN_NUMBER, num_cls(&#34;&#34;.join(num_buffer)), pos
    ), pos</code></pre>
</details>
</dd>
<dt id="tsteno.language.tokenizer.NumberTokenReader.match"><code class="name flex">
<span>def <span class="ident">match</span></span>(<span>self, character)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def match(self, character):
    return character.isdigit()</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="tsteno.language.tokenizer.StringTokenReader"><code class="flex name class">
<span>class <span class="ident">StringTokenReader</span></span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class StringTokenReader(BaseTokenReader):

    def match(self, character):
        return character == &#34;\&#34;&#34;

    def calculate(self, code, pos, max_len):
        characters = []

        pos = pos + 1
        while pos &lt; max_len:
            if code[pos] == &#34;\&#34;&#34; and code[pos - 1] != &#34;\\&#34;:
                return Token(
                    token_list.TOKEN_STRING, &#34;&#34;.join(characters), pos
                ), pos + 1
            if code[pos] == &#34;\\&#34;:
                pos = pos + 1
                continue
            characters.append(code[pos])
            pos = pos + 1

        raise TokenError(&#39;Unknown character&#39;, code, pos, max_len)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="tsteno.language.tokenizer.BaseTokenReader" href="#tsteno.language.tokenizer.BaseTokenReader">BaseTokenReader</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="tsteno.language.tokenizer.StringTokenReader.calculate"><code class="name flex">
<span>def <span class="ident">calculate</span></span>(<span>self, code, pos, max_len)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate(self, code, pos, max_len):
    characters = []

    pos = pos + 1
    while pos &lt; max_len:
        if code[pos] == &#34;\&#34;&#34; and code[pos - 1] != &#34;\\&#34;:
            return Token(
                token_list.TOKEN_STRING, &#34;&#34;.join(characters), pos
            ), pos + 1
        if code[pos] == &#34;\\&#34;:
            pos = pos + 1
            continue
        characters.append(code[pos])
        pos = pos + 1

    raise TokenError(&#39;Unknown character&#39;, code, pos, max_len)</code></pre>
</details>
</dd>
<dt id="tsteno.language.tokenizer.StringTokenReader.match"><code class="name flex">
<span>def <span class="ident">match</span></span>(<span>self, character)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def match(self, character):
    return character == &#34;\&#34;&#34;</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="tsteno.language.tokenizer.Token"><code class="flex name class">
<span>class <span class="ident">Token</span></span>
<span>(</span><span>toktype, tokval, pos)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Token:
    __slots__ = (&#39;type&#39;, &#39;val&#39;, &#39;pos&#39;)

    def __init__(self, toktype, tokval, pos):
        self.val = tokval
        self.type = toktype
        self.pos = pos

    def get_value(self):
        return self.val

    def get_type(self):
        return self.type

    def __repr__(self):
        return &#34;{} : {}&#34;.format(self.type, self.val)</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="tsteno.language.tokenizer.Token.pos"><code class="name">var <span class="ident">pos</span></code></dt>
<dd>
<div class="desc"><p>Return an attribute of instance, which is of type owner.</p></div>
</dd>
<dt id="tsteno.language.tokenizer.Token.type"><code class="name">var <span class="ident">type</span></code></dt>
<dd>
<div class="desc"><p>Return an attribute of instance, which is of type owner.</p></div>
</dd>
<dt id="tsteno.language.tokenizer.Token.val"><code class="name">var <span class="ident">val</span></code></dt>
<dd>
<div class="desc"><p>Return an attribute of instance, which is of type owner.</p></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="tsteno.language.tokenizer.Token.get_type"><code class="name flex">
<span>def <span class="ident">get_type</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_type(self):
    return self.type</code></pre>
</details>
</dd>
<dt id="tsteno.language.tokenizer.Token.get_value"><code class="name flex">
<span>def <span class="ident">get_value</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_value(self):
    return self.val</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="tsteno.language.tokenizer.TokenError"><code class="flex name class">
<span>class <span class="ident">TokenError</span></span>
<span>(</span><span>msg, code, pos, max_len)</span>
</code></dt>
<dd>
<div class="desc"><p>Common base class for all non-exit exceptions.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class TokenError(Exception):
    __slots__ = (&#39;error_message&#39;)

    def __init__(self, msg, code, pos, max_len):
        col = 0
        lin = 0
        i = 0

        while i &lt; pos:
            if code[i] == &#34;\n&#34;:
                col = 0
                lin = lin + 1
            else:
                col = col + 1
            i = i + 1

        lines = code.split(&#34;\n&#34;)

        extra_information = &#34;\n{}\n{}&#34;.format(
            lines[0], (&#39; &#39; * (col)) + &#39;^&#39;
        )

        character = code[pos] if pos &lt; max_len else &#39;EOF&#39;
        self.error_message = &#34;{} `{}` near line {} and column {}: {}&#34;.format(
            msg, character, lin + 1, col + 1, extra_information
        )

    def __str__(self):
        return self.error_message</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.Exception</li>
<li>builtins.BaseException</li>
</ul>
<h3>Instance variables</h3>
<dl>
<dt id="tsteno.language.tokenizer.TokenError.error_message"><code class="name">var <span class="ident">error_message</span></code></dt>
<dd>
<div class="desc"><p>Return an attribute of instance, which is of type owner.</p></div>
</dd>
</dl>
</dd>
<dt id="tsteno.language.tokenizer.Tokenizer"><code class="flex name class">
<span>class <span class="ident">Tokenizer</span></span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Tokenizer:
    __slots__ = (&#39;token_processors&#39;)

    def __init__(self):
        self.token_processors = [
            NumberTokenReader(), MiscTokenReader(),
            StringTokenReader(), IdentifierTokenReader()
        ]

    def skip_comments(self, pos, max_len, code):
        if pos + 1 &lt; max_len and code[pos] == &#39;(&#39; and code[pos + 1] == &#39;*&#39;:
            while pos + 1 &lt; max_len:
                if code[pos] == &#39;*&#39; and code[pos + 1] == &#39;)&#39;:
                    pos = pos + 2
                    break
                pos = pos + 1
            if pos &gt;= max_len:
                return pos, True
        return pos, False

    def skip_blankspaces(self, code, pos, max_len):
        while pos &lt; max_len and (code[pos] == &#34;\n&#34; or code[pos] == &#39; &#39;):
            pos = pos + 1

        return pos

    def get_tokens(self, code):
        pos = 0
        max_len = len(code)
        last_token = Token(token_list.TOKEN_NOTOKEN, &#39;&#39;, pos)

        while pos &lt; max_len:

            previous_pos = -1

            while previous_pos != pos:
                previous_pos = pos
                pos, ended = self.skip_comments(pos, max_len, code)
                pos = self.skip_blankspaces(code, pos, max_len)

                if pos &gt;= max_len:
                    break

            if pos &gt;= max_len:
                break

            last_token, pos = self.get_next_token(code, pos, max_len)
            yield last_token

    def get_next_token(self, code, pos, max_len):
        for processor in self.token_processors:
            if processor.match(code[pos]):
                return processor.calculate(code, pos, max_len)

        raise TokenError(&#39;Unknown character&#39;, code, pos, max_len)</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="tsteno.language.tokenizer.Tokenizer.token_processors"><code class="name">var <span class="ident">token_processors</span></code></dt>
<dd>
<div class="desc"><p>Return an attribute of instance, which is of type owner.</p></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="tsteno.language.tokenizer.Tokenizer.get_next_token"><code class="name flex">
<span>def <span class="ident">get_next_token</span></span>(<span>self, code, pos, max_len)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_next_token(self, code, pos, max_len):
    for processor in self.token_processors:
        if processor.match(code[pos]):
            return processor.calculate(code, pos, max_len)

    raise TokenError(&#39;Unknown character&#39;, code, pos, max_len)</code></pre>
</details>
</dd>
<dt id="tsteno.language.tokenizer.Tokenizer.get_tokens"><code class="name flex">
<span>def <span class="ident">get_tokens</span></span>(<span>self, code)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_tokens(self, code):
    pos = 0
    max_len = len(code)
    last_token = Token(token_list.TOKEN_NOTOKEN, &#39;&#39;, pos)

    while pos &lt; max_len:

        previous_pos = -1

        while previous_pos != pos:
            previous_pos = pos
            pos, ended = self.skip_comments(pos, max_len, code)
            pos = self.skip_blankspaces(code, pos, max_len)

            if pos &gt;= max_len:
                break

        if pos &gt;= max_len:
            break

        last_token, pos = self.get_next_token(code, pos, max_len)
        yield last_token</code></pre>
</details>
</dd>
<dt id="tsteno.language.tokenizer.Tokenizer.skip_blankspaces"><code class="name flex">
<span>def <span class="ident">skip_blankspaces</span></span>(<span>self, code, pos, max_len)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def skip_blankspaces(self, code, pos, max_len):
    while pos &lt; max_len and (code[pos] == &#34;\n&#34; or code[pos] == &#39; &#39;):
        pos = pos + 1

    return pos</code></pre>
</details>
</dd>
<dt id="tsteno.language.tokenizer.Tokenizer.skip_comments"><code class="name flex">
<span>def <span class="ident">skip_comments</span></span>(<span>self, pos, max_len, code)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def skip_comments(self, pos, max_len, code):
    if pos + 1 &lt; max_len and code[pos] == &#39;(&#39; and code[pos + 1] == &#39;*&#39;:
        while pos + 1 &lt; max_len:
            if code[pos] == &#39;*&#39; and code[pos + 1] == &#39;)&#39;:
                pos = pos + 2
                break
            pos = pos + 1
        if pos &gt;= max_len:
            return pos, True
    return pos, False</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="tsteno.language" href="index.html">tsteno.language</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="tsteno.language.tokenizer.BaseTokenReader" href="#tsteno.language.tokenizer.BaseTokenReader">BaseTokenReader</a></code></h4>
<ul class="">
<li><code><a title="tsteno.language.tokenizer.BaseTokenReader.calculate" href="#tsteno.language.tokenizer.BaseTokenReader.calculate">calculate</a></code></li>
<li><code><a title="tsteno.language.tokenizer.BaseTokenReader.match" href="#tsteno.language.tokenizer.BaseTokenReader.match">match</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="tsteno.language.tokenizer.IdentifierTokenReader" href="#tsteno.language.tokenizer.IdentifierTokenReader">IdentifierTokenReader</a></code></h4>
<ul class="">
<li><code><a title="tsteno.language.tokenizer.IdentifierTokenReader.OK_CHARACTERS" href="#tsteno.language.tokenizer.IdentifierTokenReader.OK_CHARACTERS">OK_CHARACTERS</a></code></li>
<li><code><a title="tsteno.language.tokenizer.IdentifierTokenReader.calculate" href="#tsteno.language.tokenizer.IdentifierTokenReader.calculate">calculate</a></code></li>
<li><code><a title="tsteno.language.tokenizer.IdentifierTokenReader.match" href="#tsteno.language.tokenizer.IdentifierTokenReader.match">match</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="tsteno.language.tokenizer.MiscTokenReader" href="#tsteno.language.tokenizer.MiscTokenReader">MiscTokenReader</a></code></h4>
<ul class="">
<li><code><a title="tsteno.language.tokenizer.MiscTokenReader.TOKEN_REFERENCES" href="#tsteno.language.tokenizer.MiscTokenReader.TOKEN_REFERENCES">TOKEN_REFERENCES</a></code></li>
<li><code><a title="tsteno.language.tokenizer.MiscTokenReader.calculate" href="#tsteno.language.tokenizer.MiscTokenReader.calculate">calculate</a></code></li>
<li><code><a title="tsteno.language.tokenizer.MiscTokenReader.match" href="#tsteno.language.tokenizer.MiscTokenReader.match">match</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="tsteno.language.tokenizer.NumberTokenReader" href="#tsteno.language.tokenizer.NumberTokenReader">NumberTokenReader</a></code></h4>
<ul class="">
<li><code><a title="tsteno.language.tokenizer.NumberTokenReader.calculate" href="#tsteno.language.tokenizer.NumberTokenReader.calculate">calculate</a></code></li>
<li><code><a title="tsteno.language.tokenizer.NumberTokenReader.match" href="#tsteno.language.tokenizer.NumberTokenReader.match">match</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="tsteno.language.tokenizer.StringTokenReader" href="#tsteno.language.tokenizer.StringTokenReader">StringTokenReader</a></code></h4>
<ul class="">
<li><code><a title="tsteno.language.tokenizer.StringTokenReader.calculate" href="#tsteno.language.tokenizer.StringTokenReader.calculate">calculate</a></code></li>
<li><code><a title="tsteno.language.tokenizer.StringTokenReader.match" href="#tsteno.language.tokenizer.StringTokenReader.match">match</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="tsteno.language.tokenizer.Token" href="#tsteno.language.tokenizer.Token">Token</a></code></h4>
<ul class="">
<li><code><a title="tsteno.language.tokenizer.Token.get_type" href="#tsteno.language.tokenizer.Token.get_type">get_type</a></code></li>
<li><code><a title="tsteno.language.tokenizer.Token.get_value" href="#tsteno.language.tokenizer.Token.get_value">get_value</a></code></li>
<li><code><a title="tsteno.language.tokenizer.Token.pos" href="#tsteno.language.tokenizer.Token.pos">pos</a></code></li>
<li><code><a title="tsteno.language.tokenizer.Token.type" href="#tsteno.language.tokenizer.Token.type">type</a></code></li>
<li><code><a title="tsteno.language.tokenizer.Token.val" href="#tsteno.language.tokenizer.Token.val">val</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="tsteno.language.tokenizer.TokenError" href="#tsteno.language.tokenizer.TokenError">TokenError</a></code></h4>
<ul class="">
<li><code><a title="tsteno.language.tokenizer.TokenError.error_message" href="#tsteno.language.tokenizer.TokenError.error_message">error_message</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="tsteno.language.tokenizer.Tokenizer" href="#tsteno.language.tokenizer.Tokenizer">Tokenizer</a></code></h4>
<ul class="">
<li><code><a title="tsteno.language.tokenizer.Tokenizer.get_next_token" href="#tsteno.language.tokenizer.Tokenizer.get_next_token">get_next_token</a></code></li>
<li><code><a title="tsteno.language.tokenizer.Tokenizer.get_tokens" href="#tsteno.language.tokenizer.Tokenizer.get_tokens">get_tokens</a></code></li>
<li><code><a title="tsteno.language.tokenizer.Tokenizer.skip_blankspaces" href="#tsteno.language.tokenizer.Tokenizer.skip_blankspaces">skip_blankspaces</a></code></li>
<li><code><a title="tsteno.language.tokenizer.Tokenizer.skip_comments" href="#tsteno.language.tokenizer.Tokenizer.skip_comments">skip_comments</a></code></li>
<li><code><a title="tsteno.language.tokenizer.Tokenizer.token_processors" href="#tsteno.language.tokenizer.Tokenizer.token_processors">token_processors</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.1</a>.</p>
</footer>
</body>
</html>